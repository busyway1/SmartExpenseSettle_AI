"""
í–¥ìƒëœ ë¬¸ì„œ ê°ì§€ê¸° - PyMuPDF ìŠ¤íƒ€ì¼ì˜ ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ ë¡œì§

ê° í˜ì´ì§€ë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ ë¬¸ì„œ íƒ€ì…ì„ ê°ì§€í•˜ê³ ,
ì—¬ëŸ¬ ë¬¸ì„œ íƒ€ì…ì´ ë™ì‹œì— ì¡´ì¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
"""

import re
import logging
from typing import List, Dict, Any, Tuple
from .models import DocumentType

logger = logging.getLogger(__name__)


class EnhancedDocumentDetector:
    """ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ ë¬¸ì„œ ê°ì§€ê¸°"""
    
    def __init__(self, verbose: bool = False):
        self.verbose = verbose
        
        # ì§‘ê³„ ëŒ€ìƒì—ì„œ ì œì™¸í•  ë¬¸ì„œ íŒ¨í„´ (Commercial Invoice, Packing List ë“±)
        self.excluded_patterns = [
            r'commercial\s*invoice',
            r'packing\s*list',
            r'packing\s*slip',
            r'delivery\s*note',
            r'shipping\s*note'
        ]
        
        # ê° ë¬¸ì„œ íƒ€ì…ë³„ ê³ ìœ í•œ ì‹ë³„ì íŒ¨í„´
        self.signature_patterns = {
            DocumentType.INVOICE: {
                'patterns': [
                    r'invoice\s*(?:no\.?|number)',
                    r'freight\s*(?:charge|cost)',
                    r'ìš´ì„|í™”ë¬¼ìš´ì†¡ë£Œ',
                    r'ì¸ë³´ì´ìŠ¤',
                    r'REMIT\s*TO',
                    r'CLIENT\s*NO',
                    r'CHARGEABLE\s*WGT',
                    r'expeditors',
                    r'TERMINAL\s*HANDLING',
                    r'FORWARDING\s*FEE',
                    r'DOCUMENT\s*FEE',
                    r'PROCESSING\s*FEE',
                    r'VAT\s*CATEGORY'
                ],
                'exclusions': ['ì„¸ê¸ˆê³„ì‚°ì„œ', 'tax invoice'],
                'min_score': 1
            },
            DocumentType.TAX_INVOICE: {
                'patterns': [
                    r'ì„¸ê¸ˆê³„ì‚°ì„œ',
                    r'ì˜ì„¸ìœ¨ì „ìì„¸ê¸ˆê³„ì‚°ì„œ',
                    r'ê³µê¸‰ê°€ì•¡',
                    r'ê³µê¸‰ë°›ëŠ”ì',
                    r'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸\s*\d{3}-\d{2}-\d{5}',
                    r'ë§¤ì¶œì„¸ê¸ˆê³„ì‚°ì„œ',
                    r'ë¶€ê°€ê°€ì¹˜ì„¸',
                    r'ì„¸ì•¡',
                    r'í•©ê³„ê¸ˆì•¡',
                    r'ë°œê¸‰ì¼ì',
                    r'ê³µê¸‰ììƒí˜¸',
                    r'ìŠ¹ì¸ë²ˆí˜¸.*\d+',
                    r'eTradeInvoice'
                ],
                'exclusions': [],
                'min_score': 1
            },
            DocumentType.BILL_OF_LADING: {
                'patterns': [
                    r'bill\s*of\s*lading',
                    r'b/l\s*(?:no\.?|number)',
                    r'port\s*of\s*loading',
                    r'port\s*of\s*discharge',
                    r'ì„ í•˜ì¦ê¶Œ',
                    r'vessel\s*name'
                ],
                'exclusions': [],
                'min_score': 1
            },
            DocumentType.EXPORT_DECLARATION: {
                'patterns': [
                    r'ìˆ˜ì¶œì‹ ê³ í•„ì¦',
                    r'ìˆ˜ì¶œì‹ ê³ ì„œ',
                    r'ì‹ ê³ ë²ˆí˜¸\s*\d+',
                    r'ê´€ì„¸ì²­',
                    r'export\s*declaration',
                    r'í†µê´€'
                ],
                'exclusions': [],
                'min_score': 1
            },
            DocumentType.REMITTANCE_ADVICE: {
                'patterns': [
                    r'ì´ì²´í™•ì¸ì¦',
                    r'ì†¡ê¸ˆí™•ì¸',
                    r'ì†¡ê¸ˆì¦',
                    r'ì…ê¸ˆí™•ì¸',
                    r'í™•ì¸ì¦',
                    r'ì¶œê¸ˆ|ì…ê¸ˆ',
                    r'ì†¡ê¸ˆì¼ì',
                    r'ê³„ì¢Œë²ˆí˜¸',
                    r'ì¶œê¸ˆê³„ì¢Œë²ˆí˜¸',
                    r'ì…ê¸ˆê³„ì¢Œë²ˆí˜¸',
                    r'transfer\s*confirmation',
                    r'ìŠ¹ì¸ë²ˆí˜¸\s*\d+',
                    r'í•œêµ­ì™¸í™˜ì€í–‰',
                    r'ìš°ë¦¬ì€í–‰',
                    r'ë†í˜‘|ë†ì—…í˜‘ë™ì¡°í•©'
                ],
                'exclusions': [],
                'min_score': 1
            }
        }
    
    def detect_documents_in_pages(self, text: str) -> List[Tuple[DocumentType, float, Tuple[int, int]]]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ë¬¸ì„œ ê°ì§€ - ê°œë³„ ê°ì§€ + ì§€ëŠ¥ì  ë³‘í•©
        
        Args:
            text: ì „ì²´ í…ìŠ¤íŠ¸ (í˜ì´ì§€ êµ¬ë¶„ì í¬í•¨)
            
        Returns:
            List[(ë¬¸ì„œ_íƒ€ì…, ì‹ ë¢°ë„, í˜ì´ì§€_ë²”ìœ„)]
        """
        
        # í˜ì´ì§€ë³„ë¡œ ë¶„ë¦¬
        pages = self._split_into_pages(text)
        
        if self.verbose:
            logger.info(f"ğŸ“„ ì´ {len(pages)}ê°œ í˜ì´ì§€ ë¶„ì„ ì‹œì‘")
        
        # 1ë‹¨ê³„: ê° í˜ì´ì§€ë³„ ê°œë³„ ë¬¸ì„œ ê°ì§€ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
        individual_docs = []
        for page_num, page_text in enumerate(pages, 1):
            page_docs = self._detect_individual_documents(page_text, page_num)
            individual_docs.extend(page_docs)
        
        # 2ë‹¨ê³„: ì§€ëŠ¥ì  ë³‘í•© (ë³´ìˆ˜ì  ì ‘ê·¼) - ì„ì‹œë¡œ ë¹„í™œì„±í™”
        # merged_docs = self._smart_merge_documents(individual_docs)
        merged_docs = individual_docs  # ë³‘í•©í•˜ì§€ ì•Šê³  ê°œë³„ ë¬¸ì„œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        
        if self.verbose:
            logger.info(f"ğŸ“Š ê°œë³„ ê°ì§€: {len(individual_docs)}ê°œ")
            for i, (doc_type, conf, page_range) in enumerate(individual_docs):
                logger.info(f"  ê°œë³„ {i+1}. {doc_type.value} (í˜ì´ì§€ {page_range[0]}-{page_range[1]}, ì‹ ë¢°ë„: {conf:.2f})")
            
            logger.info(f"ğŸ¯ ìµœì¢… ë³‘í•©: {len(merged_docs)}ê°œ ë¬¸ì„œ")
            for i, (doc_type, conf, page_range) in enumerate(merged_docs):
                logger.info(f"  ìµœì¢… {i+1}. {doc_type.value} (í˜ì´ì§€ {page_range[0]}-{page_range[1]}, ì‹ ë¢°ë„: {conf:.2f})")
                
            # í•„í„°ë§ëœ ë¬¸ì„œ í†µê³„
            filtered_count = len(individual_docs) - len(merged_docs)
            if filtered_count > 0:
                logger.info(f"ğŸš« í•„í„°ë§ëœ ë¬¸ì„œ: {filtered_count}ê°œ (Commercial Invoice, Packing List ë“±)")
        
        return merged_docs
    
    def _calculate_page_scores(self, page_text: str, page_num: int) -> Dict[DocumentType, Dict[str, Any]]:
        """í˜ì´ì§€ë³„ ëª¨ë“  ë¬¸ì„œ íƒ€ì… ì ìˆ˜ ê³„ì‚° (ê°ì§€ ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ)"""
        
        page_text_lower = page_text.lower()
        scores = {}
        
        if self.verbose:
            logger.info(f"ğŸ“„ í˜ì´ì§€ {page_num} ë¶„ì„ ì¤‘...")
        
        # ê° ë¬¸ì„œ íƒ€ì…ë³„ë¡œ ì ìˆ˜ ê³„ì‚°
        for doc_type, config in self.signature_patterns.items():
            score = 0
            found_patterns = []
            excluded = False
            
            # íŒ¨í„´ ë§¤ì¹­
            for pattern in config['patterns']:
                matches = re.findall(pattern, page_text_lower, re.IGNORECASE | re.MULTILINE)
                if matches:
                    score += len(matches)
                    found_patterns.append(pattern)
            
            # ì œì™¸ íŒ¨í„´ í™•ì¸
            for exclusion in config['exclusions']:
                if exclusion.lower() in page_text_lower:
                    excluded = True
                    if self.verbose:
                        logger.info(f"  âŒ {doc_type.value}: '{exclusion}' ì œì™¸ íŒ¨í„´ ë°œê²¬")
                    break
            
            # ì œì™¸ëœ ê²½ìš° ì ìˆ˜ë¥¼ 0ìœ¼ë¡œ ì„¤ì •
            if excluded:
                score = 0
            
            scores[doc_type] = {
                'score': score,
                'found_patterns': found_patterns,
                'excluded': excluded,
                'meets_threshold': score >= config['min_score'] and not excluded
            }
            
            if self.verbose and score > 0:
                logger.info(f"  ğŸ“Š {doc_type.value}: {score}ì  {'âœ…' if scores[doc_type]['meets_threshold'] else 'âš ï¸'}")
        
        return scores
    
    def _detect_document_boundaries(self, page_scores: List[Tuple[int, str, Dict[DocumentType, Dict[str, Any]]]]) -> List[Tuple[DocumentType, float, Tuple[int, int]]]:
        """ë¬¸ì„œ ê²½ê³„ ê°ì§€ ë° ì™„ì „í•œ í˜ì´ì§€ ë²”ìœ„ ì¶”ì¶œ"""
        
        detected_docs = []
        
        # ê° ë¬¸ì„œ íƒ€ì…ë³„ë¡œ ì²˜ë¦¬
        for doc_type in DocumentType:
            if doc_type == DocumentType.UNKNOWN:
                continue
                
            # í•´ë‹¹ ë¬¸ì„œ íƒ€ì…ì˜ ê°•ë ¥í•œ ì‹ í˜¸ê°€ ìˆëŠ” í˜ì´ì§€ë“¤ ì°¾ê¸°
            strong_pages = []
            weak_pages = []
            
            for page_num, page_text, scores in page_scores:
                score_info = scores.get(doc_type, {})
                score = score_info.get('score', 0)
                meets_threshold = score_info.get('meets_threshold', False)
                
                if meets_threshold:
                    strong_pages.append(page_num)
                elif score > 0:  # ì•½í•œ ì‹ í˜¸ì§€ë§Œ ê´€ë ¨ íŒ¨í„´ ì¡´ì¬
                    weak_pages.append(page_num)
            
            # ê°•ë ¥í•œ ì‹ í˜¸ê°€ ìˆëŠ” í˜ì´ì§€ë“¤ì„ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œ ë²”ìœ„ í™•ì¥
            if strong_pages:
                doc_ranges = self._expand_document_ranges(strong_pages, weak_pages, len(page_scores))
                
                for start_page, end_page in doc_ranges:
                    # í•´ë‹¹ ë²”ìœ„ì˜ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
                    total_score = 0
                    valid_pages = 0
                    
                    for page_num in range(start_page, end_page + 1):
                        if page_num <= len(page_scores):
                            page_score = page_scores[page_num - 1][2].get(doc_type, {}).get('score', 0)
                            total_score += page_score
                            valid_pages += 1
                    
                    if valid_pages > 0:
                        avg_score = total_score / valid_pages
                        confidence = min(0.9, avg_score / 5)  # 5ì  ë§Œì ìœ¼ë¡œ ì •ê·œí™”
                        
                        detected_docs.append((doc_type, confidence, (start_page, end_page)))
                        
                        if self.verbose:
                            logger.info(f"âœ… {doc_type.value} ê°ì§€: í˜ì´ì§€ {start_page}-{end_page} (í‰ê· ì ìˆ˜: {avg_score:.1f}, ì‹ ë¢°ë„: {confidence:.2f})")
        
        # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        detected_docs.sort(key=lambda x: x[1], reverse=True)
        
        return detected_docs
    
    def _expand_document_ranges(self, strong_pages: List[int], weak_pages: List[int], total_pages: int) -> List[Tuple[int, int]]:
        """ê°•ë ¥í•œ ì‹ í˜¸ í˜ì´ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œ ë²”ìœ„ í™•ì¥ (ë³´ìˆ˜ì  ì ‘ê·¼)"""
        
        if not strong_pages:
            return []
        
        strong_pages.sort()
        weak_pages.sort()
        
        ranges = []
        
        # ë³´ìˆ˜ì  ê·¸ë£¹í™”: ì—°ì†ëœ í˜ì´ì§€ë§Œ ê·¸ë£¹í™” (ê°„ê²© í—ˆìš© ì¶•ì†Œ)
        groups = []
        current_group = [strong_pages[0]]
        
        for i in range(1, len(strong_pages)):
            if strong_pages[i] <= current_group[-1] + 1:  # 1í˜ì´ì§€ ì´ë‚´ ê°„ê²©ë§Œ í—ˆìš© (ê¸°ì¡´ 2 â†’ 1)
                current_group.append(strong_pages[i])
            else:
                groups.append(current_group)
                current_group = [strong_pages[i]]
        groups.append(current_group)
        
        # ê° ê·¸ë£¹ë³„ë¡œ ìµœì†Œí•œì˜ ë²”ìœ„ í™•ì¥
        for group in groups:
            start_page = group[0]
            end_page = group[-1]
            
            # ë³´ìˆ˜ì  í™•ì¥: ìµœëŒ€ 1í˜ì´ì§€ê¹Œì§€ë§Œ (ê¸°ì¡´ 3 â†’ 1)
            # ì•ìª½ìœ¼ë¡œ í™•ì¥ (ì•½í•œ ì‹ í˜¸ í˜ì´ì§€ í¬í•¨)
            for weak_page in reversed(weak_pages):
                if weak_page < start_page and weak_page >= start_page - 1:  # ìµœëŒ€ 1í˜ì´ì§€ ì•ê¹Œì§€
                    start_page = weak_page
                    break
            
            # ë’¤ìª½ìœ¼ë¡œ í™•ì¥ (ì•½í•œ ì‹ í˜¸ í˜ì´ì§€ í¬í•¨)
            for weak_page in weak_pages:
                if weak_page > end_page and weak_page <= end_page + 1:  # ìµœëŒ€ 1í˜ì´ì§€ ë’¤ê¹Œì§€
                    end_page = weak_page
                    break  # ì²« ë²ˆì§¸ë§Œ í¬í•¨í•˜ê³  ì¤‘ë‹¨
            
            ranges.append((start_page, end_page))
        
        return ranges
    
    def _detect_individual_documents(self, page_text: str, page_num: int) -> List[Tuple[DocumentType, float, Tuple[int, int]]]:
        """ê°œë³„ í˜ì´ì§€ì—ì„œ ë¬¸ì„œ ê°ì§€ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""
        
        page_text_lower = page_text.lower()
        detected = []
        
        if self.verbose:
            logger.info(f"ğŸ“„ í˜ì´ì§€ {page_num} ê°œë³„ ë¶„ì„ ì¤‘...")
        
        # ê° ë¬¸ì„œ íƒ€ì…ë³„ë¡œ ê²€ì‚¬
        for doc_type, config in self.signature_patterns.items():
            score = 0
            found_patterns = []
            
            # íŒ¨í„´ ë§¤ì¹­
            for pattern in config['patterns']:
                matches = re.findall(pattern, page_text_lower, re.IGNORECASE | re.MULTILINE)
                if matches:
                    score += len(matches)
                    found_patterns.append(pattern)
            
            # ì œì™¸ íŒ¨í„´ í™•ì¸ (ë¬¸ì„œ íƒ€ì…ë³„)
            excluded = False
            for exclusion in config['exclusions']:
                if exclusion.lower() in page_text_lower:
                    excluded = True
                    if self.verbose:
                        logger.info(f"  âŒ {doc_type.value}: '{exclusion}' ì œì™¸ íŒ¨í„´ ë°œê²¬")
                    break
            
            # ì „ì—­ ì œì™¸ íŒ¨í„´ í™•ì¸ (Commercial Invoice, Packing List ë“±) - ì„ì‹œë¡œ ë¹„í™œì„±í™”
            # if not excluded:
            #     for excluded_pattern in self.excluded_patterns:
            #         if re.search(excluded_pattern, page_text_lower, re.IGNORECASE):
            #             excluded = True
            #             if self.verbose:
            #                 logger.info(f"  âŒ {doc_type.value}: '{excluded_pattern}' ì „ì—­ ì œì™¸ íŒ¨í„´ ë°œê²¬")
            #             break
            
            # ì ìˆ˜ê°€ ì„ê³„ê°’ ì´ìƒì´ê³  ì œì™¸ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ê°ì§€
            if score >= config['min_score'] and not excluded:
                confidence = min(0.9, score / 5)  # 5ì  ë§Œì ìœ¼ë¡œ ì •ê·œí™”
                detected.append((doc_type, confidence, (page_num, page_num)))
                
                if self.verbose:
                    logger.info(f"  âœ… {doc_type.value}: {score}ì  (ì‹ ë¢°ë„: {confidence:.2f})")
                    logger.info(f"     ë°œê²¬ëœ íŒ¨í„´: {found_patterns}")
        
        return detected
    
    def _smart_merge_documents(self, individual_docs: List[Tuple[DocumentType, float, Tuple[int, int]]]) -> List[Tuple[DocumentType, float, Tuple[int, int]]]:
        """ì§€ëŠ¥ì  ë¬¸ì„œ ë³‘í•© (ì—„ê²©í•œ ì¡°ê±´)"""
        
        if not individual_docs:
            return []
        
        # í˜ì´ì§€ ìˆœìœ¼ë¡œ ì •ë ¬
        individual_docs.sort(key=lambda x: x[2][0])
        
        # ë³‘í•©í•˜ì§€ ì•Šì„ ë¬¸ì„œ íƒ€ì… (ì¼ë°˜ì ìœ¼ë¡œ ë‹¨ì¼ í˜ì´ì§€)
        no_merge_types = {
            DocumentType.TAX_INVOICE,      # ì„¸ê¸ˆê³„ì‚°ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ í•œ ì¥
            DocumentType.REMITTANCE_ADVICE # ì†¡ê¸ˆì¦ë„ ì¼ë°˜ì ìœ¼ë¡œ í•œ ì¥
        }
        
        merged = []
        i = 0
        
        while i < len(individual_docs):
            current_type, current_conf, (start, end) = individual_docs[i]
            
            # ë³‘í•©í•˜ì§€ ì•Šì„ ë¬¸ì„œ íƒ€ì…ì€ ê°œë³„ ì²˜ë¦¬
            if current_type in no_merge_types:
                merged.append((current_type, current_conf, (start, end)))
                i += 1
                continue
            
            # ì—°ì†ëœ í˜ì´ì§€ í™•ì¸ ë° ë¬¸ì„œ ì‹ë³„ì ìœ ì‚¬ì„± ê²€ì‚¬
            j = i + 1
            while j < len(individual_docs):
                next_type, next_conf, (next_start, next_end) = individual_docs[j]
                
                # 1. ë™ì¼í•œ ë¬¸ì„œ íƒ€ì…ì´ê³  ë°”ë¡œ ë‹¤ìŒ í˜ì´ì§€ì¸ ê²½ìš°ë§Œ ë³‘í•© í›„ë³´
                if (next_type == current_type and 
                    next_start == end + 1):  # ë°”ë¡œ ë‹¤ìŒ í˜ì´ì§€
                    
                    # 2. ë¬¸ì„œ ì‹ë³„ì ìœ ì‚¬ì„± ê²€ì‚¬ (í˜ì´ì§€ ë‚´ìš© ê¸°ë°˜)
                    if self._should_merge_documents(current_type, start, next_start):
                        end = next_end
                        current_conf = max(current_conf, next_conf)  # ë†’ì€ ì‹ ë¢°ë„ ìœ ì§€
                        j += 1
                    else:
                        # ì‹ë³„ìê°€ ë‹¤ë¥´ë©´ ë³‘í•©í•˜ì§€ ì•ŠìŒ
                        break
                else:
                    break
            
            merged.append((current_type, current_conf, (start, end)))
            i = j
        
        return merged
    
    def _should_merge_documents(self, doc_type: DocumentType, page1: int, page2: int) -> bool:
        """ë¬¸ì„œ ì‹ë³„ì ìœ ì‚¬ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ë³‘í•© ì—¬ë¶€ ê²°ì •"""
        
        # í˜„ì¬ëŠ” ê°„ë‹¨í•œ ë¡œì§ìœ¼ë¡œ êµ¬í˜„
        # ì‹¤ì œë¡œëŠ” í˜ì´ì§€ ë‚´ìš©ì—ì„œ B/L NO, Invoice NO ë“±ì„ ì¶”ì¶œí•˜ì—¬ ë¹„êµí•´ì•¼ í•¨
        # ì—¬ê¸°ì„œëŠ” ë³´ìˆ˜ì ìœ¼ë¡œ ì ‘ê·¼: ê¸°ë³¸ì ìœ¼ë¡œ ë³‘í•©í•˜ì§€ ì•ŠìŒ
        
        # íŠ¹ì • ë¬¸ì„œ íƒ€ì…ë§Œ ë³‘í•© í—ˆìš© (ë§¤ìš° ë³´ìˆ˜ì )
        mergeable_types = {
            DocumentType.BILL_OF_LADING,     # B/Lì€ ì—¬ëŸ¬ í˜ì´ì§€ì¼ ìˆ˜ ìˆìŒ
            DocumentType.EXPORT_DECLARATION  # ìˆ˜ì¶œì‹ ê³ í•„ì¦ë„ ì—¬ëŸ¬ í˜ì´ì§€ì¼ ìˆ˜ ìˆìŒ
        }
        
        if doc_type not in mergeable_types:
            return False
        
        # TODO: ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í˜ì´ì§€ ë‚´ìš©ì—ì„œ ë¬¸ì„œ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ë¹„êµ
        # ì§€ê¸ˆì€ ë§¤ìš° ë³´ìˆ˜ì ìœ¼ë¡œ ë³‘í•©í•˜ì§€ ì•ŠìŒ
        return False
    
    def _split_into_pages(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ í˜ì´ì§€ë³„ë¡œ ë¶„ë¦¬ (PyMuPDF ìŠ¤íƒ€ì¼)"""
        
        # í˜ì´ì§€ êµ¬ë¶„ìë¡œ ë¶„ë¦¬
        page_separators = [
            r'--- í˜ì´ì§€ \d+ ---',
            r'page \d+',
            r'\n\s*\d+\s*\n',  # í˜ì´ì§€ ë²ˆí˜¸ë§Œ ìˆëŠ” ì¤„
        ]
        
        pages = [text]  # ê¸°ë³¸ê°’: ì „ì²´ë¥¼ í•˜ë‚˜ì˜ í˜ì´ì§€ë¡œ
        
        for separator in page_separators:
            new_pages = []
            for page in pages:
                parts = re.split(separator, page, flags=re.IGNORECASE)
                new_pages.extend([part.strip() for part in parts if part.strip()])
            
            if len(new_pages) > len(pages):
                pages = new_pages
                break
        
        # ë¹ˆ í˜ì´ì§€ ì œê±°
        pages = [page for page in pages if len(page.strip()) > 50]
        
        return pages
    
    def _merge_consecutive_documents(self, detected_docs: List[Tuple[DocumentType, float, Tuple[int, int]]]) -> List[Tuple[DocumentType, float, Tuple[int, int]]]:
        """ì—°ì†ëœ ê°™ì€ ë¬¸ì„œ íƒ€ì… ë³‘í•©"""
        
        if not detected_docs:
            return []
        
        # í˜ì´ì§€ ìˆœìœ¼ë¡œ ì •ë ¬
        detected_docs.sort(key=lambda x: x[2][0])
        
        merged = []
        
        i = 0
        while i < len(detected_docs):
            current_type, current_conf, (start, end) = detected_docs[i]
            
            # ì—°ì†ëœ ê°™ì€ ë¬¸ì„œ íƒ€ì… ì°¾ê¸°
            j = i + 1
            while j < len(detected_docs):
                next_type, next_conf, (next_start, next_end) = detected_docs[j]
                
                if (next_type == current_type and 
                    next_start <= end + 1):  # ì—°ì†ëœ í˜ì´ì§€
                    end = max(end, next_end)
                    current_conf = max(current_conf, next_conf)  # ë†’ì€ ì‹ ë¢°ë„ ìœ ì§€
                    j += 1
                else:
                    break
            
            merged.append((current_type, current_conf, (start, end)))
            i = j
        
        return merged
    
    def get_debug_info(self, text: str) -> Dict[str, Any]:
        """ë””ë²„ê¹… ì •ë³´ ë°˜í™˜"""
        
        pages = self._split_into_pages(text)
        debug_info = {
            "total_pages": len(pages),
            "page_lengths": [len(page) for page in pages],
            "detected_patterns": {}
        }
        
        # ê° í˜ì´ì§€ë³„ íŒ¨í„´ ë§¤ì¹­ ì •ë³´
        for page_num, page_text in enumerate(pages, 1):
            page_text_lower = page_text.lower()
            page_patterns = {}
            
            for doc_type, config in self.signature_patterns.items():
                found = []
                for pattern in config['patterns']:
                    matches = re.findall(pattern, page_text_lower, re.IGNORECASE)
                    if matches:
                        found.append(f"{pattern}: {len(matches)}ê°œ")
                
                if found:
                    page_patterns[doc_type.value] = found
            
            if page_patterns:
                debug_info["detected_patterns"][f"page_{page_num}"] = page_patterns
        
        return debug_info